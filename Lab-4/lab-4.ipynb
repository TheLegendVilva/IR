{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment - 4 : Text classification Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1.0 Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups = fetch_20newsgroups(subset='all', shuffle=True, remove=('headers', 'footers', 'quotes'))\n",
    "X_train, X_test, y_train, y_test = train_test_split(newsgroups.data, newsgroups.target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenisation, stemming and text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Preprocessed Text from X_train:\n",
      "# # 've gotten post group last coupl day . ( # recent ad feed list . ) , group # near death ? # seen mail list side , 'm get right amount traffic . patrick l. mahan -- - tgv window washer -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - mahan @ tgv.com -- -- -- -- - wake person unnecessarili consid - lazaru long capit crime . first offens , notebook lazaru long patrick l. mahan -- - tgv window washer -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - mahan @ tgv.com -- -- -- -- -\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK stop words if not already downloaded\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# Initialize the Porter Stemmer for stemming\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Tokenization, stemming, and stop words removal function\n",
    "def preprocess_text(text):\n",
    "    words = word_tokenize(text)\n",
    "    filtered_words = [word for word in words if word.lower() not in stopwords.words('english')]\n",
    "    stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
    "    processed_text = \" \".join(stemmed_words)\n",
    "    return processed_text\n",
    "\n",
    "# Preprocess the entire dataset\n",
    "X_train_preprocessed = [preprocess_text(text) for text in X_train]\n",
    "X_test_preprocessed = [preprocess_text(text) for text in X_test]\n",
    "\n",
    "# Print the preprocessed texts\n",
    "print(\"Sample Preprocessed Text from X_train:\")\n",
    "print(X_train_preprocessed[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1.1 Preprocessing using tfidf vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_preprocessed)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_preprocessed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1.2 Naive-Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_tfidf, y_train)\n",
    "y_pred_nb = nb_classifier.predict(X_test_tfidf)\n",
    "f1_nb = f1_score(y_test, y_pred_nb, average='weighted')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1.3 Rocchio classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocchio_classifier(X_train, y_train, X_test):\n",
    "    # Calculate the centroids for each class\n",
    "    classes = np.unique(y_train)\n",
    "    centroids = {}\n",
    "    for c in classes:\n",
    "        class_indices = np.where(y_train == c)[0]\n",
    "        centroids[c] = np.mean(X_train[class_indices], axis=0)\n",
    "\n",
    "    # Classify test data using Rocchio\n",
    "    y_pred = []\n",
    "    for sample in X_test:\n",
    "        best_class = None\n",
    "        best_distance = float('inf')\n",
    "        for c in classes:\n",
    "            distance = np.linalg.norm(sample - centroids[c])\n",
    "            if distance < best_distance:\n",
    "                best_distance = distance\n",
    "                best_class = c\n",
    "        y_pred.append(best_class)\n",
    "    return np.array(y_pred)\n",
    "\n",
    "# Train and predict using the Rocchio classifier\n",
    "y_pred_rocchio = rocchio_classifier(X_train_tfidf, y_train, X_test_tfidf)\n",
    "\n",
    "# Calculate F-score for the Rocchio classifier\n",
    "f1_rocchio = f1_score(y_test, y_pred_rocchio, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1.4 KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "k = 5  # Adjust the value of k as needed\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "knn_classifier.fit(X_train_tfidf, y_train)\n",
    "y_pred_knn = knn_classifier.predict(X_test_tfidf)\n",
    "f1_knn = f1_score(y_test, y_pred_knn, average='weighted')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 F-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score Naive Bayes: 0.6973481022239094\n",
      "F-score Rocchio: 0.6664976418174576\n",
      "F-score k-Nearest Neighbor (k=5): 0.08855796706083052\n"
     ]
    }
   ],
   "source": [
    "print(f\"F-score Naive Bayes: {f1_nb}\")\n",
    "print(f\"F-score Rocchio: {f1_rocchio}\")\n",
    "print(f\"F-score k-Nearest Neighbor (k={k}): {f1_knn}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
